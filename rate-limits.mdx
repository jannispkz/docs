---
title: "Rate Limits"
description: "Understanding and working with API rate limits"
---

## Overview

The Pikzels API implements rate limiting to ensure fair usage and maintain service quality for all users.

<Info>
  **Default Limit:** Maximum of **10 concurrent requests** per API key
  
  **Enterprise:** Higher limits available upon request - [contact us](mailto:support@pikzels.com)
</Info>

## How Rate Limiting Works

### Concurrent Request Model

Unlike traditional rate limits based on requests per minute, Pikzels uses a concurrent request model:

- You can have up to 10 requests processing at the same time
- Once a request completes, that slot becomes available immediately
- There's no time window - it's purely based on active concurrent requests

### Example Scenario

```
Step 1: Send 10 requests
        → All 10 accepted ✓ (all slots occupied)

Step 2: Request #1 completes
        → 1 slot opens, can send 1 more

Step 3: Requests #2-4 complete
        → 3 slots open, can send 3 more

Step 4: Try to send 4 requests
        → 3 accepted, 1 rejected (at 10-slot limit)
```

## Handling Rate Limits

### Rate Limit Response

When you exceed the concurrent request limit, you'll receive a `429` error:

```json
{
  "error": {
    "code": "CONCURRENT_LIMIT_EXCEEDED",
    "message": "Concurrent Request Limit Reached",
    "details": "Maximum of 10 concurrent requests allowed. Please wait for existing requests to complete"
  }
}
```

### Best Practices

<AccordionGroup>
  <Accordion title="Implement Request Queuing" icon="list">
    Queue requests to stay within limits:
    
    ```javascript
    class PikzelsQueue {
      constructor(maxConcurrent = 10) {
        this.maxConcurrent = maxConcurrent;
        this.currentRequests = 0;
        this.queue = [];
      }
      
      async request(endpoint, data) {
        while (this.currentRequests >= this.maxConcurrent) {
          await new Promise(resolve => setTimeout(resolve, 100));
        }
        
        this.currentRequests++;
        try {
          const response = await fetch(endpoint, {
            method: 'POST',
            headers: {
              'X-Api-Key': process.env.PIKZELS_API_KEY,
              'Content-Type': 'application/json'
            },
            body: JSON.stringify(data)
          });
          return await response.json();
        } finally {
          this.currentRequests--;
        }
      }
    }
    
    const queue = new PikzelsQueue(10);
    const result = await queue.request('https://api.pikzels.com/v1/thumbnail', data);
    ```
  </Accordion>
  
  <Accordion title="Use Exponential Backoff" icon="chart-line">
    Retry failed requests with increasing delays:
    
    ```python
    import time
    import requests
    
    def request_with_retry(url, headers, data, max_retries=5):
        for attempt in range(max_retries):
            response = requests.post(url, headers=headers, json=data)
            
            if response.status_code == 429:
                # Exponential backoff: 1s, 2s, 4s, 8s, 16s
                wait_time = 2 ** attempt
                print(f"Rate limited. Waiting {wait_time}s...")
                time.sleep(wait_time)
                continue
            
            return response
        
        raise Exception("Max retries exceeded")
    ```
  </Accordion>
  
  <Accordion title="Batch Processing" icon="layer-group">
    Process large batches efficiently:
    
    ```python
    import asyncio
    import aiohttp
    
    class PikzelsBatcher:
        def __init__(self, api_key, max_concurrent=10):
            self.api_key = api_key
            self.semaphore = asyncio.Semaphore(max_concurrent)
        
        async def process_single(self, session, data):
            async with self.semaphore:
                headers = {
                    'X-Api-Key': self.api_key,
                    'Content-Type': 'application/json'
                }
                async with session.post(
                    'https://api.pikzels.com/v1/thumbnail',
                    headers=headers,
                    json=data
                ) as response:
                    return await response.json()
        
        async def process_batch(self, items):
            async with aiohttp.ClientSession() as session:
                tasks = [self.process_single(session, item) for item in items]
                return await asyncio.gather(*tasks)
    
    # Process 100 items, max 10 concurrent
    batcher = PikzelsBatcher('pkz_your_api_key')
    results = await batcher.process_batch(items)
    ```
  </Accordion>
  
  <Accordion title="Monitor Active Requests" icon="activity">
    Track your concurrent request count:
    
    ```javascript
    class RequestMonitor {
      constructor() {
        this.activeRequests = new Set();
      }
      
      async makeRequest(id, endpoint, data) {
        this.activeRequests.add(id);
        console.log(`Active requests: ${this.activeRequests.size}/10`);
        
        try {
          const response = await fetch(endpoint, {
            method: 'POST',
            headers: headers,
            body: JSON.stringify(data)
          });
          return await response.json();
        } finally {
          this.activeRequests.delete(id);
        }
      }
      
      canMakeRequest() {
        return this.activeRequests.size < 10;
      }
    }
    ```
  </Accordion>
</AccordionGroup>

## Optimizing for Rate Limits

### Strategies for High-Volume Applications

1. **Request Pooling**
   - Combine multiple operations when possible
   - Use the most efficient endpoints for your use case

2. **Caching**
   - Cache generated images locally
   - Implement a CDN for frequently accessed content
   - Use cache headers appropriately

3. **Predictive Generation**
   - Generate content during off-peak hours
   - Pre-generate common variations
   - Queue non-urgent requests

4. **Load Distribution**
   - Spread requests over time
   - Implement priority queues
   - Use multiple API keys for different services/environments

## Rate Limit Headers

Monitor these response headers to track your usage:

```http
X-RateLimit-Limit: 10
X-RateLimit-Remaining: 7
X-RateLimit-Reset: 1640995200
```

<Note>
  Headers may vary. Check actual API responses for current header names.
</Note>

## Common Patterns

### Sequential Processing

For non-time-critical operations:

```javascript
async function processSequentially(items) {
  const results = [];
  for (const item of items) {
    const result = await makeApiCall(item);
    results.push(result);
  }
  return results;
}
```

### Parallel with Limit

For optimal throughput:

```javascript
async function processWithLimit(items, limit = 10) {
  const results = [];
  for (let i = 0; i < items.length; i += limit) {
    const batch = items.slice(i, i + limit);
    const batchResults = await Promise.all(
      batch.map(item => makeApiCall(item))
    );
    results.push(...batchResults);
  }
  return results;
}
```

### Priority Queue

For mixed priority requests:

```javascript
class PriorityQueue {
  constructor() {
    this.high = [];
    this.normal = [];
    this.low = [];
  }
  
  add(item, priority = 'normal') {
    this[priority].push(item);
  }
  
  next() {
    if (this.high.length) return this.high.shift();
    if (this.normal.length) return this.normal.shift();
    if (this.low.length) return this.low.shift();
    return null;
  }
}
```

## Troubleshooting

### Frequently Hit Rate Limits?

Consider these solutions:

1. **Optimize Request Patterns**
   - Batch similar requests
   - Eliminate duplicate requests
   - Cache results aggressively

2. **Upgrade Your Plan**
   - Contact sales for higher limits
   - Discuss enterprise options

3. **Architectural Changes**
   - Implement request queuing
   - Add a caching layer
   - Use webhooks for async processing

## Error Handling Example

Complete implementation with proper error handling:

```python
import asyncio
import aiohttp
from typing import List, Dict, Any

class PikzelsClient:
    def __init__(self, api_key: str, max_concurrent: int = 10):
        self.api_key = api_key
        self.semaphore = asyncio.Semaphore(max_concurrent)
        self.base_url = "https://api.pikzels.com"
        
    async def _make_request(
        self,
        session: aiohttp.ClientSession,
        endpoint: str,
        data: Dict[str, Any]
    ) -> Dict[str, Any]:
        async with self.semaphore:
            headers = {
                'X-Api-Key': self.api_key,
                'Content-Type': 'application/json'
            }
            
            for attempt in range(5):  # Max 5 retries
                async with session.post(
                    f"{self.base_url}{endpoint}",
                    headers=headers,
                    json=data
                ) as response:
                    if response.status == 429:
                        # Rate limited - exponential backoff
                        wait_time = 2 ** attempt
                        await asyncio.sleep(wait_time)
                        continue
                    
                    if response.status == 200:
                        return await response.json()
                    
                    # Other errors
                    error_data = await response.json()
                    raise Exception(f"API Error: {error_data}")
            
            raise Exception("Max retries exceeded for rate limit")
    
    async def generate_thumbnails(
        self,
        prompts: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        async with aiohttp.ClientSession() as session:
            tasks = [
                self._make_request(session, "/v1/thumbnail", prompt)
                for prompt in prompts
            ]
            return await asyncio.gather(*tasks, return_exceptions=True)

# Usage
client = PikzelsClient("pkz_your_api_key")
results = await client.generate_thumbnails(prompts)
```

## Need Higher Limits?

The default 10 concurrent request limit can be increased for enterprise customers based on your specific needs.

### How to Get Higher Limits

1. **Contact our team** at [support@pikzels.com](mailto:support@pikzels.com)
2. **Provide details about:**
   - Your use case and application
   - Expected request volume
   - Peak concurrent requests needed
   - Current API usage patterns
3. **We'll work with you to:**
   - Determine appropriate limits for your needs
   - Set up enterprise pricing
   - Provide dedicated support

<CardGroup cols={2}>
  <Card
    title="Enterprise Solutions"
    icon="building"
    href="mailto:support@pikzels.com"
  >
    Custom rate limits tailored to your requirements
  </Card>
  <Card
    title="Dedicated Support"
    icon="headset"
    href="mailto:support@pikzels.com"
  >
    Priority support and SLA guarantees
  </Card>
</CardGroup>

### Enterprise Benefits

- **Custom concurrent request limits** - 50, 100, or more based on your needs
- **Priority queue access** - Your requests get processed first
- **Dedicated infrastructure** - Optional dedicated processing resources
- **SLA guarantees** - Uptime and response time commitments
- **Direct support channel** - Slack or dedicated support contact
- **Volume discounts** - Better pricing for high-volume usage